{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6738092-d30c-4983-9605-517baafd003b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 18:30:42.645851: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from generator_class_multi_1226 import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "050d0705-4cf6-4ca5-9928-070a04641436",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-23 20:07:07.077664: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# trying to get list of url list to work \n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import zlib\n",
    "import glob\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, optimizers, callbacks, losses\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "import keras.backend as K\n",
    "import os\n",
    "from generator_class_multi_1226 import DataGenerator_3output_train, DataGenerator_3output_test\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import json\n",
    "import tqdm\n",
    "import argparse\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from weighted_scce import * #custom weighted loss function for class imbalance. \n",
    "\n",
    "#GPU/CPU Selection\n",
    "gpu_setting = 'y'\n",
    "random.seed(42) # reproducibility \n",
    "# Set the number of threads\n",
    "num_threads = 8\n",
    "tf.config.threading.set_inter_op_parallelism_threads(num_threads)\n",
    "\n",
    "### CHANGE PATH (or remove it, I can remake the plots as long as you save the model.) \n",
    "plt.style.use('/home/sophiaf/mystyle.mplstyle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535a9ebc-eb23-44f7-b342-587ce6a9db98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c342821-7665-4f2c-bd9e-af34db21546b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52931b7-ead5-4f96-b542-5fb5890e4200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36f1d528-760a-43b5-a026-9a7fd156db22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-23 20:07:11.673645: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-23 20:07:11.705326: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-23 20:07:11.705639: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-23 20:07:11.706477: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-23 20:07:11.712609: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-23 20:07:11.712891: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-23 20:07:11.713134: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-23 20:07:12.092506: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-23 20:07:12.092863: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-23 20:07:12.093108: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-23 20:07:12.093344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 18168 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe MIG 2g.20gb, pci bus id: 0000:06:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "model_path = '/home/sophiaf/Classification-with-ML/neutrino-classification/CNN/model_save/ResNet_20240204/'\n",
    "loaded_model = tf.keras.models.load_model(model_path, custom_objects={'WeightedSCCE': WeightedSCCE_for_saving})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850e65f6-7ee0-4aff-999d-a7d7a00a00ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('/Users/aaronhiguera/HEP/DUNE/DUNE_CNN/ResNet_20240204/', \n",
    "                                   custom_objects={'WeightedSCCE':WeightedSCCE(), \n",
    "                                                   'output_loss_weights':output_loss_weights, 'output_losses':output_losses} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "443a4fbe-7dd4-477b-a15e-b68e6fdbf596",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('/home/sophiaf/pixel_maps_val/preprocessed_filelists/secondbatch_df_testset.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0bf16b82-b477-42d2-b157-430d01cb948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = DataGenerator_3output_test(df.iloc[:6400], 64, (200,200),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2742642-fdae-4f71-89ac-6c85a0ab8cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 13s 120ms/step - loss: nan - flavour_loss: 0.2487 - protons_loss: 0.6328 - pions_loss: nan - flavour_accuracy: 0.9070 - protons_accuracy: 0.7291 - pions_accuracy: 0.8616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[nan,\n",
       " 0.2486628144979477,\n",
       " 0.6328144073486328,\n",
       " nan,\n",
       " 0.907031238079071,\n",
       " 0.7290624976158142,\n",
       " 0.8615624904632568]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.evaluate(test_gen, verbose=1)\n",
    "# note that the loss function will be messed up. but for what we care about, that is ok. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7504a803-b2ad-46ea-8a66-3b975f12ba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar -cvf cvn_atmnu.tar.gz /home/sophiaf/Classification-with-ML/neutrino-classification/CNN/model_save/ResNet_20240204"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "330e41ce-35f1-4b6a-9ea6-f68c3aae55bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No such layer: whatami. Existing layers are: ['input_1', 'conv2d', 'batch_normalization', 're_lu', 'max_pooling2d', 'conv2d_1', 'batch_normalization_1', 're_lu_1', 'conv2d_2', 'batch_normalization_2', 'add', 're_lu_2', 'conv2d_3', 'batch_normalization_3', 're_lu_3', 'conv2d_4', 'batch_normalization_4', 'conv2d_5', 'add_1', 're_lu_4', 'conv2d_6', 'batch_normalization_5', 're_lu_5', 'conv2d_7', 'batch_normalization_6', 'conv2d_8', 'add_2', 're_lu_6', 'conv2d_9', 'batch_normalization_7', 're_lu_7', 'conv2d_10', 'batch_normalization_8', 'conv2d_11', 'add_3', 're_lu_8', 'conv2d_12', 'batch_normalization_9', 're_lu_9', 'conv2d_13', 'batch_normalization_10', 'conv2d_14', 'add_4', 're_lu_10', 'global_average_pooling2d', 'dense', 'dense_1', 'flavour', 'protons', 'pions'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mloaded_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwhatami\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py:3353\u001b[0m, in \u001b[0;36mModel.get_layer\u001b[0;34m(self, name, index)\u001b[0m\n\u001b[1;32m   3351\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m name:\n\u001b[1;32m   3352\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m layer\n\u001b[0;32m-> 3353\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3354\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such layer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Existing layers are: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3355\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(layer\u001b[38;5;241m.\u001b[39mname\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mlayer\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3356\u001b[0m     )\n\u001b[1;32m   3357\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3358\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvide either a layer name or layer index at `get_layer`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3359\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: No such layer: whatami. Existing layers are: ['input_1', 'conv2d', 'batch_normalization', 're_lu', 'max_pooling2d', 'conv2d_1', 'batch_normalization_1', 're_lu_1', 'conv2d_2', 'batch_normalization_2', 'add', 're_lu_2', 'conv2d_3', 'batch_normalization_3', 're_lu_3', 'conv2d_4', 'batch_normalization_4', 'conv2d_5', 'add_1', 're_lu_4', 'conv2d_6', 'batch_normalization_5', 're_lu_5', 'conv2d_7', 'batch_normalization_6', 'conv2d_8', 'add_2', 're_lu_6', 'conv2d_9', 'batch_normalization_7', 're_lu_7', 'conv2d_10', 'batch_normalization_8', 'conv2d_11', 'add_3', 're_lu_8', 'conv2d_12', 'batch_normalization_9', 're_lu_9', 'conv2d_13', 'batch_normalization_10', 'conv2d_14', 'add_4', 're_lu_10', 'global_average_pooling2d', 'dense', 'dense_1', 'flavour', 'protons', 'pions']."
     ]
    }
   ],
   "source": [
    "loaded_model.get_layer('whatami')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7925890d-392c-43dd-953a-e36b7b1972ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot iterate over a tensor with unknown first dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m loaded_model\u001b[38;5;241m.\u001b[39msignatures[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserving_default\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39minputs:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput key:\u001b[39m\u001b[38;5;124m'\u001b[39m, key, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShape:\u001b[39m\u001b[38;5;124m'\u001b[39m, value\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDType:\u001b[39m\u001b[38;5;124m'\u001b[39m, value\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:585\u001b[0m, in \u001b[0;36mTensor.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    583\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot iterate over a scalar tensor.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 585\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    586\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot iterate over a tensor with unknown first dimension.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _TensorIterator(\u001b[38;5;28mself\u001b[39m, shape[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot iterate over a tensor with unknown first dimension."
     ]
    }
   ],
   "source": [
    "for key, value in loaded_model.signatures['serving_default'].inputs.items():\n",
    "    print('Input key:', key, 'Shape:', value.shape, 'DType:', value.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2e09b80-26a4-4bd7-9bd7-e5f4ac70c6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'Identity:0' shape=(None, 3) dtype=float32>,\n",
       " <tf.Tensor 'Identity_1:0' shape=(None, 2) dtype=float32>,\n",
       " <tf.Tensor 'Identity_2:0' shape=(None, 4) dtype=float32>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.signatures['serving_default'].outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8ded0d-7eeb-4ae0-bb68-5d850351d135",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in model.signatures['serving_default'].outputs.items():\n",
    "    print('Output key:', key, 'Shape:', value.shape, 'DType:', value.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58c6027-92e0-4189-85bb-878fc2d9d922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48f54243-6171-49cb-8386-a23fc24a60fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x, filters, kernel_size=3, stride=1):\n",
    "    # Shortcut connection\n",
    "    shortcut = x\n",
    "\n",
    "    # First convolution layer\n",
    "    x = layers.Conv2D(filters, kernel_size, strides=stride, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # Second convolution layer\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # If the number of filters has changed, apply a 1x1 convolution to the shortcut\n",
    "    if shortcut.shape[-1] != filters:\n",
    "        shortcut = layers.Conv2D(filters, 1, padding='same', kernel_initializer='he_normal')(shortcut)\n",
    "    \n",
    "    # Add the shortcut to the output\n",
    "    x = layers.Add()([x, shortcut])\n",
    "    x = layers.ReLU()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "356612a2-f848-44d0-b3ed-398a569fc64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = 3\n",
    "dimensions = (200,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb93ef82-7a71-466a-9454-5735b5246482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 18:30:47.493359: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-12 18:30:47.530231: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-12 18:30:47.530555: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-12 18:30:47.531604: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-12 18:30:47.549293: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-12 18:30:47.549604: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-12 18:30:47.549887: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-12 18:30:47.939009: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-12 18:30:47.939391: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-12 18:30:47.939663: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-12 18:30:47.939929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 18168 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe MIG 2g.20gb, pci bus id: 0000:06:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "input_shape = (dimensions[0], dimensions[1], n_channels)\n",
    "inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "# Initial Convolution Layer\n",
    "x = layers.Conv2D(32, 7, strides=2, padding='same', kernel_initializer='he_normal')(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "\n",
    "# Residual Blocks\n",
    "num_blocks = 5  # Increase the number of residual blocks\n",
    "filters = [32, 64, 128, 256, 512]   # Increase the number of filters in each block\n",
    "\n",
    " \n",
    "for i in range(num_blocks):\n",
    "    x = residual_block(x, filters[i])\n",
    "\n",
    "# Global Average Pooling Layer\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Fully connected (Dense) layers\n",
    "x = layers.Dense(128, activation='relu', kernel_initializer='he_normal')(x)\n",
    "x = layers.Dense(64, activation='sigmoid', kernel_initializer='he_normal')(x)\n",
    "\n",
    "# Output layer, 3 classifications (no nu_tau) plus sub-class cases. \n",
    "output_names=['flavour','protons','pions']\n",
    "output_neurons=[3,4,2]\n",
    "\n",
    "outputs = [None]*len(output_names)\n",
    "for i in range(len(outputs)):\n",
    "    activation='sigmoid' if output_neurons[i]==1 else 'softmax'\n",
    "    weight_decay = 1e-4\n",
    "    outputs[i] = layers.Dense(output_neurons[i], use_bias=False, kernel_regularizer=l2(weight_decay),\n",
    "                       activation=activation, name=output_names[i])(x)\n",
    "model = models.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17920190-da11-42dd-ba3e-8969083d7427",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = [{0: 1.48/(1.48+1+1.18), 1: 1./(1.48+1+1.18), 2: 1.18/(1.48+1+1.18)},\n",
    "                 {0: 1.31/(1.31+1+3+5), 1: 1./(1.31+1+3+5), 2: 3./(1.31+1+3+5), 3: 5./(1.31+1+3+5)},\n",
    "                 {0: 1./(1.+2), 1: 2./(1+2.)},\n",
    "                 ]\n",
    "\n",
    "class_weights_tensors = [tf.constant(list(weights.values()), dtype=tf.float32) for weights in class_weights]\n",
    "\n",
    "output_losses = {\n",
    "\"flavour\": WeightedSCCE_for_saving(class_weight=class_weights_tensors[0]), # \"sparse_categorical_crossentropy\",\n",
    "\"protons\":  WeightedSCCE_for_saving(class_weight=class_weights_tensors[1]),\n",
    "\"pions\":  WeightedSCCE_for_saving(class_weight=class_weights_tensors[2]),\n",
    "}\n",
    "output_loss_weights = {\"flavour\": 1.0, \"protons\": 1.0, \"pions\": 1.0, }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "782d26b0-8cef-4f7c-9946-20520b8e1ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_optimizer = SGD(learning_rate=1e-4, momentum=0.9)\n",
    "model.compile(optimizer=sgd_optimizer,\n",
    "                  loss = output_losses,\n",
    "                  loss_weights = output_loss_weights,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e3cde5f-8f89-4e47-b390-0d72a9dc22f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_path_tf = '/home/sophiaf/temp_model_save_tf/'  \n",
    "temp_path = '/home/sophiaf/temp_model_save/'  \n",
    "\n",
    "# model.save(temp_path_tf, save_format='tf')\n",
    "# model.save(temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c8f89b0-5a20-47e3-9f8b-430afa7d8e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loaded_model = tf.keras.models.load_model(temp_path_tf, custom_objects={'WeightedSCCE_for_saving': WeightedSCCE_for_saving})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e0c2fe-ffad-48da-881b-c62efdd71ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cd7fbd-b85d-411a-ba0a-0d2a8a31c53c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "py3-preamble"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
